{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "id": "CrjZ-Ma78a0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch_lightning\n",
      "  Downloading pytorch_lightning-2.0.1-py3-none-any.whl (716 kB)\n",
      "\u001b[K     |████████████████████████████████| 716 kB 1.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.0.0 in /Users/matthewiskornev/opt/anaconda3/lib/python3.9/site-packages (from pytorch_lightning) (4.1.1)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in /Users/matthewiskornev/opt/anaconda3/lib/python3.9/site-packages (from pytorch_lightning) (0.11.1)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /Users/matthewiskornev/opt/anaconda3/lib/python3.9/site-packages (from pytorch_lightning) (4.64.0)\n",
      "Requirement already satisfied: fsspec[http]>2021.06.0 in /Users/matthewiskornev/opt/anaconda3/lib/python3.9/site-packages (from pytorch_lightning) (2022.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /Users/matthewiskornev/opt/anaconda3/lib/python3.9/site-packages (from pytorch_lightning) (1.21.5)\n",
      "Requirement already satisfied: packaging>=17.1 in /Users/matthewiskornev/opt/anaconda3/lib/python3.9/site-packages (from pytorch_lightning) (21.3)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/matthewiskornev/opt/anaconda3/lib/python3.9/site-packages (from pytorch_lightning) (1.13.1)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /Users/matthewiskornev/opt/anaconda3/lib/python3.9/site-packages (from pytorch_lightning) (6.0)\n",
      "Collecting lightning-utilities>=0.7.0\n",
      "  Downloading lightning_utilities-0.8.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: requests in /Users/matthewiskornev/opt/anaconda3/lib/python3.9/site-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (2.27.1)\n",
      "Requirement already satisfied: aiohttp in /Users/matthewiskornev/opt/anaconda3/lib/python3.9/site-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (3.8.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/matthewiskornev/opt/anaconda3/lib/python3.9/site-packages (from packaging>=17.1->pytorch_lightning) (3.0.4)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /Users/matthewiskornev/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->fsspec[http]>2021.06.0->pytorch_lightning) (2.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/matthewiskornev/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->fsspec[http]>2021.06.0->pytorch_lightning) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/matthewiskornev/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->fsspec[http]>2021.06.0->pytorch_lightning) (21.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/matthewiskornev/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->fsspec[http]>2021.06.0->pytorch_lightning) (1.6.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/matthewiskornev/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->fsspec[http]>2021.06.0->pytorch_lightning) (4.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/matthewiskornev/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->fsspec[http]>2021.06.0->pytorch_lightning) (1.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/matthewiskornev/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->fsspec[http]>2021.06.0->pytorch_lightning) (5.2.0)\n",
      "Requirement already satisfied: idna>=2.0 in /Users/matthewiskornev/opt/anaconda3/lib/python3.9/site-packages (from yarl<2.0,>=1.0->aiohttp->fsspec[http]>2021.06.0->pytorch_lightning) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/matthewiskornev/opt/anaconda3/lib/python3.9/site-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/matthewiskornev/opt/anaconda3/lib/python3.9/site-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (1.26.9)\n",
      "Installing collected packages: lightning-utilities, pytorch-lightning\n",
      "Successfully installed lightning-utilities-0.8.0 pytorch-lightning-2.0.1\n",
      "Requirement already satisfied: tensorboardX in /Users/matthewiskornev/opt/anaconda3/lib/python3.9/site-packages (2.6)\n",
      "Requirement already satisfied: numpy in /Users/matthewiskornev/opt/anaconda3/lib/python3.9/site-packages (from tensorboardX) (1.21.5)\n",
      "Requirement already satisfied: protobuf<4,>=3.8.0 in /Users/matthewiskornev/opt/anaconda3/lib/python3.9/site-packages (from tensorboardX) (3.19.1)\n",
      "Requirement already satisfied: packaging in /Users/matthewiskornev/opt/anaconda3/lib/python3.9/site-packages (from tensorboardX) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/matthewiskornev/opt/anaconda3/lib/python3.9/site-packages (from packaging->tensorboardX) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch_lightning\n",
    "!pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1CmEukeg8Njd"
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as td\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import tqdm\n",
    "import json\n",
    "import sklearn.metrics as sm\n",
    "\n",
    "import tensorboardX as tb\n",
    "import tensorflow as tf\n",
    "import datetime, os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "np.random.seed(31337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O4cLf0zW8Njf"
   },
   "source": [
    "## Create pairs (first track, subsequent track, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "DHUIFjU0Z09C"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MKlgAqq-8Njg"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"/content/drive/MyDrive/recsys-itmo-2023/seminar_05/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y9aeehkP8Njh"
   },
   "outputs": [],
   "source": [
    "data = pd.read_json(DATA_DIR + \"data.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zj9JftT88Njh"
   },
   "outputs": [],
   "source": [
    "Pair = namedtuple(\"Session\", [\"user\", \"start\", \"track\", \"time\"])\n",
    "\n",
    "def get_pairs(user_data):\n",
    "    pairs = []\n",
    "    first = None\n",
    "    for _, row in user_data.sort_values(\"timestamp\").iterrows():\n",
    "        if first is None:\n",
    "            first = row[\"track\"]\n",
    "        else:\n",
    "            pairs.append(Pair(row[\"user\"], first, row[\"track\"], row[\"time\"]))\n",
    "        \n",
    "        if row[\"message\"] == \"last\":\n",
    "            first = None\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4c_Ifi9_8Nji"
   },
   "outputs": [],
   "source": [
    "pairs = pd.DataFrame(\n",
    "    data\n",
    "    .groupby(\"user\")\n",
    "    .apply(get_pairs)\n",
    "    .explode()\n",
    "    .values\n",
    "    .tolist(),\n",
    "    columns=[\"user\", \"start\", \"track\", \"time\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eA0LzG3Z8Nji"
   },
   "outputs": [],
   "source": [
    "figure, ax = plt.subplots()\n",
    "sns.histplot(pairs[\"time\"], ax=ax)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PkYDflFK8Njj"
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cE63YQAi8Njj"
   },
   "outputs": [],
   "source": [
    "rdm = np.random.random(len(pairs))\n",
    "train_data = pairs[rdm < 0.8]\n",
    "val_data = pairs[(rdm >= 0.8) & (rdm < 0.9)]\n",
    "test_data = pairs[rdm >= 0.9]\n",
    "\n",
    "len(train_data), len(val_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2N72w3Ym8Njl"
   },
   "outputs": [],
   "source": [
    "class ContextualRanker(pl.LightningModule):\n",
    "    def __init__(self, embedding_dim=10):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        # We won't have embeddings for everything, but that's ok\n",
    "        self.context = nn.Embedding(num_embeddings=50000, embedding_dim=self.embedding_dim)\n",
    "        self.track = nn.Embedding(num_embeddings=50000, embedding_dim=self.embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        context = self.context(x[:, 0]) # start track\n",
    "        track = self.track(x[:, 1]) # next track\n",
    "        return torch.sum(context * track, dim=1)\n",
    "            \n",
    "    def step(self, batch, batch_idx, metric, prog_bar=False):\n",
    "        x, y = batch\n",
    "        predictions = self.forward(x)\n",
    "        loss = F.mse_loss(predictions, y.float(), reduction='mean')\n",
    "        self.log(metric, loss, prog_bar=prog_bar)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx, prog_bar=False):\n",
    "        x, y = batch\n",
    "        predictions = self.forward(x)\n",
    "        targets = y[:, 0].float()\n",
    "        avgs = y[:, 1].float()\n",
    "        rdms = y[:, 2].float()\n",
    "\n",
    "        loss = F.mse_loss(predictions, targets, reduction='mean')\n",
    "        avg_loss = F.mse_loss(avgs, targets, reduction='mean')\n",
    "        rdm_loss = F.mse_loss(rdms, targets, reduction='mean')\n",
    "\n",
    "        self.log(\"test_loss\", loss, prog_bar=prog_bar)\n",
    "        self.log(\"avg_loss\", avg_loss, prog_bar=prog_bar)\n",
    "        self.log(\"rdm_loss\", rdm_loss, prog_bar=prog_bar)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.step(batch, batch_idx, \"train_loss\")\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.step(batch, batch_idx, \"val_loss\", True)\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True)\n",
    "        scheduler = {\n",
    "            'scheduler': lr_scheduler,\n",
    "            'reduce_on_plateau': True,\n",
    "            'monitor': 'val_loss'\n",
    "        }\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XSZTEW7h9d3p"
   },
   "outputs": [],
   "source": [
    "class ContextualRankerData(pl.LightningDataModule):\n",
    "    def __init__(self, train_data, val_data, test_data, features):\n",
    "        super().__init__()\n",
    "        self.train_data = train_data\n",
    "        self.val_data = val_data\n",
    "        self.test_data = test_data\n",
    "        self.features = features\n",
    "\n",
    "    def prepare_data(self):\n",
    "        self.test_data = self.test_data.assign(rdm = np.random.random(len(self.test_data))).assign(avg = self.train_data[\"time\"].mean())\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        if stage == \"fit\" or stage is None:\n",
    "        self.train_dataset = td.TensorDataset(\n",
    "            torch.from_numpy(self.train_data[self.features].values), \n",
    "            torch.from_numpy(self.train_data[\"time\"].values)\n",
    "            )\n",
    "\n",
    "        self.val_dataset = td.TensorDataset(\n",
    "            torch.from_numpy(self.val_data[self.features].values), \n",
    "            torch.from_numpy(self.val_data[\"time\"].values)\n",
    "            )\n",
    "\n",
    "        if stage == \"test\" or stage is None:  \n",
    "        self.test_dataset = td.TensorDataset(\n",
    "            torch.from_numpy(self.test_data[self.features].values),\n",
    "            torch.from_numpy(self.test_data[[\"time\", \"avg\", \"rdm\"]].values)\n",
    "        )\n",
    "    def train_dataloader(self):\n",
    "        return td.DataLoader(self.train_dataset, batch_size=2048, shuffle=True, num_workers=0)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return td.DataLoader(self.val_dataset, batch_size=2048, num_workers=0)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return td.DataLoader(self.test_dataset, batch_size=512, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JWZ8cqTZ8Njm"
   },
   "outputs": [],
   "source": [
    "net = ContextualRanker(embedding_dim=100)\n",
    "data_module = ContextualRankerData(train_data, val_data, test_data, features = [\"start\", \"track\"])\n",
    "\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(monitor=\"val_loss\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=300,\n",
    "    accelerator='gpu', \n",
    "    devices=1,\n",
    "    callbacks=[\n",
    "        pl.callbacks.early_stopping.EarlyStopping(monitor=\"val_loss\", patience=5),\n",
    "        pl.callbacks.LearningRateMonitor(logging_interval=\"step\"),\n",
    "        checkpoint_callback\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "omCmoxVhGfJ2"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /content/lightning_logs --host localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sqy8qDr98Njm"
   },
   "outputs": [],
   "source": [
    "trainer.fit(\n",
    "    net, \n",
    "    data_module\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_IeB7jzb8Njn"
   },
   "outputs": [],
   "source": [
    "best = ContextualRanker.load_from_checkpoint(checkpoint_callback.best_model_path, embedding_dim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HTUgc8_hQ7N0"
   },
   "outputs": [],
   "source": [
    "trainer.test(best, data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tRZLUR9_8Njo"
   },
   "source": [
    "## Compute top recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5UrLSjgt8Njo"
   },
   "outputs": [],
   "source": [
    "track_meta = pd.read_json(DATA_DIR + \"tracks.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PqwVsVyO8Njp"
   },
   "outputs": [],
   "source": [
    "context_embeddings = dict(best.named_parameters())[\"context.weight\"].data.cpu().numpy()\n",
    "track_embeddings = dict(best.named_parameters())[\"track.weight\"].data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-z1VTPGh8Njp"
   },
   "outputs": [],
   "source": [
    "track_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m7_A20no8Njp"
   },
   "outputs": [],
   "source": [
    "k = 100\n",
    "with open(DATA_DIR + \"tracks_with_recs.json\", \"w\") as rf:\n",
    "    for _, track in tqdm.tqdm(track_meta.iterrows()):\n",
    "        embedding = context_embeddings[track[\"track\"]]\n",
    "        neighbours = np.argpartition(-np.dot(track_embeddings, embedding), k)[:k]\n",
    "        \n",
    "        recommendation = dict(track)\n",
    "        recommendation[\"recommendations\"] = neighbours.tolist()\n",
    "        \n",
    "        rf.write(json.dumps(recommendation) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QhS_o_ff8Njp"
   },
   "outputs": [],
   "source": [
    "track = 3916\n",
    "embedding = context_embeddings[track]\n",
    "track_meta.loc[track_meta[\"track\"] == track, [\"artist\", \"title\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gGFHEN8g8Njq"
   },
   "outputs": [],
   "source": [
    "k = 10\n",
    "neighbours = np.argpartition(-np.dot(track_embeddings, embedding), k)[:k]\n",
    "track_meta.loc[track_meta[\"track\"].isin(neighbours), [\"artist\", \"title\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ymCblQht8Njq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
